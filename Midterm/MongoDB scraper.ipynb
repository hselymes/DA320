{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Fetched 506429 characters from https://www.metacritic.com/browse/movies/score/metascore/year.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import urllib3\n",
    "import certifi\n",
    "import re\n",
    "import json\n",
    "import pymongo\n",
    "import pandas\n",
    "import time\n",
    "\n",
    "# Define source link\n",
    "link = 'https://www.metacritic.com/browse/movies/score/metascore/year'\n",
    "\n",
    "# Define regex\n",
    "title_regex = re.compile(r\"class=\\\"title\\\"><h3>(.+)</h3>\")\n",
    "releaseDate_regex = re.compile(r\"class=\\\"clamp-details\\\">\\s+<span>(.+)<\\/span>\")\n",
    "description_regex = re.compile(r\"<div class=\\\"summary\\\">\\s+(.+)\\s+\")\n",
    "metascore_regex = re.compile(r\"<div class=\\\"clamp-score-wrap\\\">\\s*.*\\s<div class=\\\"metascore_w large movie (positive|mixed|negative)\\\">(.*)<\\/div>\")\n",
    "photoURL_regex = re.compile(r\"<a href=\\\".*<img\\ssrc=\\\"(https.*)\\\" alt\")\n",
    "\n",
    "# Build a python request pool\n",
    "http = urllib3.PoolManager(cert_reqs = 'CERT_NONE')\n",
    "\n",
    "# Fix SSL cert error \n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# Intiate a web request\n",
    "res = http.request('GET', link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "# Convert results from raw bytes to test\n",
    "datastring = str(res.data, \"utf-8\")\n",
    "\n",
    "# Check for success and how much data retrieved from the site\n",
    "print(f'Status: {res.status}')\n",
    "print(f'Fetched {len(datastring)} characters from {link}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My secret key is 67 characters in length.\n"
     ]
    }
   ],
   "source": [
    "# Loading the json file that containins my secret MongoDB connection string\n",
    "with open (r'C:\\Users\\hsely\\OneDrive\\Documents\\GitHub\\DA320\\Midterm\\credentials.json') as u:\n",
    "    data = json.load(u)\n",
    "\n",
    "secret_key = data['mongodb']\n",
    "\n",
    "# We can safely print the length of the secret key. That won't leak any sensitive information.\n",
    "print(f\"My secret key is {len(secret_key)} characters in length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MongoDB version 5.0.13.\n",
      "This database has the collections ['Metacritic', 'IMDB', 'IMDB_Pipeline_View']\n"
     ]
    }
   ],
   "source": [
    "# Code by Vincent Hong\n",
    "# Connecting to the database using known good certificates\n",
    "client = pymongo.MongoClient(secret_key, tlsCAFile=certifi.where())\n",
    "\n",
    "# Fetching my database titled \"DA320\"\n",
    "da320_database = client.DA320\n",
    "metacritic_data = da320_database.Metacritic\n",
    "\n",
    "# Accessing my collections from my \"DA320\" database\n",
    "allCollections = da320_database.list_collection_names()\n",
    "\n",
    "# Print statements that display the current version as well as the collections present in DA320\n",
    "print(f\"Using MongoDB version {client.server_info()['version']}.\")\n",
    "print(f\"This database has the collections {allCollections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of movies from a particular year and page of Metacritic\n",
    "def metacritic_scraper(year: int, page: int) -> pandas.DataFrame:\n",
    "    \n",
    "    # Fetch webpage\n",
    "    url = \"https://www.metacritic.com/browse/movies/score/metascore/year/filtered?year_selected={year}&sort=desc&view=detailed&page={page}\"\n",
    "    response = http.request('GET', url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    datastring = str(response.data, \"utf-8\")\n",
    "\n",
    "    # Execute all regex\n",
    "    titles = title_regex.findall(datastring)\n",
    "    dates = releaseDate_regex.findall(datastring)\n",
    "    descriptions = description_regex.findall(datastring)\n",
    "    scores = metascore_regex.findall(datastring)\n",
    "    images = photoURL_regex.findall(datastring)\n",
    "\n",
    "    # Return a unified collection\n",
    "    dataset = {\"title\": titles, \"date\": dates, \"description\": descriptions, \"score\": scores, \"image\": images}\n",
    "    return pandas.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for 2000 page 0...\n",
      "Inserting 0 movies for the year 2000 page 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "documents must be a non-empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [142], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Insert records into MongoDB\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInserting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(movies_to_insert)\u001b[39m}\u001b[39;00m\u001b[39m movies for the year \u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m page \u001b[39m\u001b[39m{\u001b[39;00mpage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m metacritic_data\u001b[39m.\u001b[39;49minsert_many(movies_to_insert)\n\u001b[0;32m     29\u001b[0m page \u001b[39m=\u001b[39m page \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hsely\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\_csot.py:105\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[39mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    104\u001b[0m             \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hsely\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\collection.py:691\u001b[0m, in \u001b[0;36mCollection.insert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session, comment)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39m\"\"\"Insert an iterable of documents.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m \u001b[39m  >>> db.test.count_documents({})\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[39m.. versionadded:: 3.0\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    687\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(documents, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m    688\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(documents, abc\u001b[39m.\u001b[39mMapping)\n\u001b[0;32m    689\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m documents\n\u001b[0;32m    690\u001b[0m ):\n\u001b[1;32m--> 691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdocuments must be a non-empty list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    692\u001b[0m inserted_ids: List[ObjectId] \u001b[39m=\u001b[39m []\n\u001b[0;32m    694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen\u001b[39m():\n",
      "\u001b[1;31mTypeError\u001b[0m: documents must be a non-empty list"
     ]
    }
   ],
   "source": [
    "# Write a CSV file with this data\n",
    "for year in range(2000, 2023):\n",
    "    page = 0\n",
    "    print(f\"Collecting data for {year} page {page}...\")\n",
    "\n",
    "    #Retry a page multiple times if necessary\n",
    "    while True:\n",
    "        data = metacritic_scraper(year, page)\n",
    "\n",
    "        # Stop at page with zero rows\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "    #Convert the dataframe into a list of movies to insert into Mongo DB\n",
    "    movies_to_insert = []\n",
    "    for row in data.itertuples():\n",
    "        movie = {\n",
    "            \"title\": row.title,\n",
    "            \"release_date\": row.date,\n",
    "            \"description\": row.description, \n",
    "            \"metascore\": row.score, \n",
    "            \"image_url\": row.image,\n",
    "        }\n",
    "        movies_to_insert.append(movie)\n",
    "    \n",
    "    # Insert records into MongoDB\n",
    "    print(f\"Inserting {len(movies_to_insert)} movies for the year {year} page {page}\")\n",
    "    metacritic_data.insert_many(movies_to_insert)\n",
    "    page = page + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define title to search movie Title\n",
    "title = r\"class=\\\"title\\\"><h3>(.+)</h3>\"\n",
    "\n",
    "# Find matches within text \n",
    "matches = re.findall(title, datastring)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regular_expression to search movie Release date\n",
    "releaseDate = r\"class=\\\"clamp-details\\\">\\s+<span>(.+)<\\/span>\"\n",
    "\n",
    "# Find matches within text \n",
    "matches = re.findall(releaseDate, datastring)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define description to search movie Description\n",
    "description = r\"<div class=\\\"summary\\\">\\s+(.+)\\s+\"\n",
    "\n",
    "# Find matches within text \n",
    "matches = re.findall(description, datastring)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metascore to search movie Metascore\n",
    "metascore = r\"<div class=\\\"clamp-score-wrap\\\">\\s*.*\\s<div class=\\\"metascore_w large movie (positive|mixed|negative)\\\">(.*)<\\/div>\"\n",
    "\n",
    "# Find matches within text \n",
    "matches = re.findall(metascore, datastring)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define photoURL to search movie Photo URL\n",
    "# Code by Vincent Hong\n",
    "photoURL = r\"<a href=\\\".*<img\\ssrc=\\\"(https.*)\\\" alt\"\n",
    "\n",
    "# Find matches within text \n",
    "matches = re.findall(photoURL, datastring)\n",
    "print(f\"Found {len(matches)} matches.  The first match is '{matches[0]}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b1cd541dce40554fcef1bc164db90e16f02abe413750f3aa4cd39cb144a0ed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
