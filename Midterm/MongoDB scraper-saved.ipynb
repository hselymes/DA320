{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Scraper for Metacritic movie data\n",
    "DA 230 Midterm\n",
    "\n",
    "Author: Heather Marie\n",
    "\n",
    "Contributers: Ted Spence, Vincent Hong, Jamie Kirsila, Natalia Sadkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Fetched 505994 characters from https://www.metacritic.com/browse/movies/score/metascore/year.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import urllib3\n",
    "import certifi\n",
    "import re\n",
    "import json\n",
    "import pymongo\n",
    "import pandas\n",
    "\n",
    "# Define source link\n",
    "link = f'https://www.metacritic.com/browse/movies/score/metascore/year'\n",
    "\n",
    "# Define regex\n",
    "title_regex = re.compile(r\"class=\\\"title\\\"><h3>(.+)</h3>\")\n",
    "date_regex = re.compile(r\"class=\\\"clamp-details\\\">\\s+<span>(.+)<\\/span>\")\n",
    "description_regex = re.compile(r\"<div class=\\\"summary\\\">\\s*([\\S\\s]+?)\\s*<\\div>\")\n",
    "score_regex = re.compile(r\"<span class=\\\"title\\\">Metascore:</span>\\s+<a class=\\\"metascore_anchor\\\" href=\\\"/movie/.*?/critic-reviews\\\">\\s+<div class=\\\"metascore_w large movie .+\\\">(.*?)</div>\")\n",
    "image_regex = re.compile(r\"<a href=\\\"/movie/.*\\\"><img\\src=\\\"(.*)\\\" alt\")\n",
    "\n",
    "# Build a python request pool\n",
    "http = urllib3.PoolManager(cert_reqs = 'CERT_NONE')\n",
    "\n",
    "# Fix SSL cert error \n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# Intiate a web request\n",
    "res = http.request('GET', link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "# Convert results from raw bytes to test\n",
    "datastring = str(res.data, \"utf-8\")\n",
    "\n",
    "# Check for success and how much data retrieved from the site\n",
    "print(f'Status: {res.status}')\n",
    "print(f'Fetched {len(datastring)} characters from {link}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My secret key is 67 characters in length.\n"
     ]
    }
   ],
   "source": [
    "# Loading the json file that containins my secret MongoDB connection string\n",
    "with open (r'C:\\Users\\hsely\\OneDrive\\Documents\\GitHub\\DA320\\Midterm\\credentials.json') as u:\n",
    "    data = json.load(u)\n",
    "\n",
    "secret_key = data['mongodb']\n",
    "\n",
    "# We can safely print the length of the secret key. That won't leak any sensitive information.\n",
    "print(f\"My secret key is {len(secret_key)} characters in length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MongoDB version 5.0.13.\n",
      "This database has the collections ['IMDB', 'IMDB_Pipeline_View']\n"
     ]
    }
   ],
   "source": [
    "# Connecting to the database using known good certificates\n",
    "client = pymongo.MongoClient(secret_key, tlsCAFile=certifi.where())\n",
    "\n",
    "# Fetching my database titled \"DA320\"\n",
    "da320_database = client.DA320\n",
    "metacritic_data = da320_database.Metacritic\n",
    "\n",
    "# Accessing my collections from my \"DA320\" database\n",
    "allCollections = da320_database.list_collection_names()\n",
    "\n",
    "# Print statements that display the current version as well as the collections present in DA320\n",
    "print(f\"Using MongoDB version {client.server_info()['version']}.\")\n",
    "print(f\"This database has the collections {allCollections}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of movies from a particular year and page of Metacritic\n",
    "def metacritic_scraper(year: int, page: int) -> pandas.DataFrame:\n",
    "    \n",
    "    # Fetch webpage\n",
    "    url = f\"https://www.metacritic.com/browse/movies/score/metascore/year/filtered?year_selected={year}&sort=desc&view=detailed&page={page}\"\n",
    "    response = http.request('GET', url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    datastring = str(response.data, \"utf-8\")\n",
    "\n",
    "    # Execute all regex\n",
    "    titles = title_regex.findall(datastring)\n",
    "    dates = date_regex.findall(datastring)\n",
    "    descriptions = description_regex.findall(datastring)\n",
    "    scores = score_regex.findall(datastring)\n",
    "    images = image_regex.findall(datastring)\n",
    "\n",
    "    # Return a unified collection\n",
    "    dataset = {\"title\": titles, \"date\": dates, \"description\": descriptions, \"score\": scores, \"image\": images}\n",
    "    return pandas.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for 2000 page 0...\n"
     ]
    }
   ],
   "source": [
    "# Write a CSV file with this data\n",
    "for year in range(2000, 2023):\n",
    "    page = 0\n",
    "    print(f\"Collecting data for {year} page {page}...\")\n",
    "\n",
    "    #Retry a page multiple times if necessary\n",
    "    while True:\n",
    "        data = metacritic_scraper(year, page)\n",
    "\n",
    "        # Stop at page with zero rows\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "\n",
    "        #Convert the dataframe into a list of movies to insert into Mongo DB\n",
    "        movies_to_insert = []\n",
    "        for row in data.itertuples():\n",
    "            movie = {\n",
    "                \"title\": row.title,\n",
    "                \"release_date\": row.date,\n",
    "                \"description\": row.description, \n",
    "                \"metascore\": row.score, \n",
    "                \"image_url\": row.image,\n",
    "            }\n",
    "            movies_to_insert.append(movie)\n",
    "        \n",
    "        # Insert records into MongoDB\n",
    "        print(f\"Inserting {len(movies_to_insert)} movies for the year {year} page {page}\")\n",
    "        metacritic_data.insert_many(movies_to_insert)\n",
    "        page = page + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b1cd541dce40554fcef1bc164db90e16f02abe413750f3aa4cd39cb144a0ed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
